#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import aiohttp
import asyncio
import logging
import os
import re
import sys
import time
import datetime
import random
import csv
from bs4 import BeautifulSoup
from typing import Dict, List, Any, Optional, Set, Tuple
from urllib.parse import urljoin
import psycopg2
from psycopg2.extras import RealDictCursor

# 導入自定義的 User-Agent 列表
from user_agents import USER_AGENTS

# 設置默認編碼為 UTF-8
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# 設定日誌
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("atmovies_movie_scraper_v2.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# 常數設定
BASE_URL = "https://www.atmovies.com.tw/"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
    'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Connection': 'keep-alive',
    'Cache-Control': 'no-cache',
    'Pragma': 'no-cache',
    'Referer': 'https://www.atmovies.com.tw/',
    'sec-ch-ua': '"Google Chrome";v="123", "Not:A-Brand";v="8", "Chromium";v="123"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"macOS"',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'same-origin',
    'Sec-Fetch-User': '?1',
    'Upgrade-Insecure-Requests': '1'
}
TIMEOUT = 30  # 增加請求超時時間至 30 秒
MAX_CONCURRENT_REQUESTS = 5  # 降低並發請求數至 5
MAX_RETRIES = 3  # 最大重試次數
RETRY_DELAY = 3  # 重試間隔時間(秒)

# 資料庫連接資訊
DB_URL = "postgresql://time2cinema_db_user:wUsukaH2Kiy8fIejuOqsk5yjn4FBb0RX@dpg-d0e9e749c44c73co4lsg-a.singapore-postgres.render.com/time2cinema_db"

# 電影清單頁面
FIRST_RUN_URL = "https://www.atmovies.com.tw/movie/now/1/"
SECOND_RUN_URL = "https://www.atmovies.com.tw/movie/now2/1/"

class ATMoviesMovieScraper:
    """ATMovies 電影爬蟲"""
    def __init__(self):
        self.conn = None
        self.cursor = None
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)  # 限制並發請求數
        self.session = None  # 用於非同步HTTP請求的session
        self.movie_details_cache = {}  # 快取已爬取的電影詳情
        
    async def connect_to_db(self) -> bool:
        """連接到資料庫"""
        try:
            # 建立資料庫連接，並設定編碼為 UTF-8
            self.conn = psycopg2.connect(
                DB_URL,
                sslmode='require',
                client_encoding='UTF8'  # 設定客戶端編碼為 UTF-8
            )
            self.conn.autocommit = False
            self.cursor = self.conn.cursor(cursor_factory=RealDictCursor)
            
            # 確保資料庫連接的編碼為 UTF-8
            self.cursor.execute("SET client_encoding TO 'UTF8'")
            self.conn.commit()
            
            logger.info("成功連接到資料庫")
            return True
        except Exception as e:
            logger.error(f"連接資料庫時出錯: {e}")
            return False
    
    def close_db_connection(self):
        """關閉資料庫連接"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()
            logger.info("資料庫連接已關閉")
            
    async def create_session(self):
        """創建HTTP會話"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession(headers=HEADERS)
        return self.session
    
    async def close_session(self):
        """關閉HTTP會話"""
        if self.session and not self.session.closed:
            await self.session.close()
            logger.info("非同步HTTP session已關閉")
            
    async def fetch_page(self, url: str) -> Optional[BeautifulSoup]:
        """獲取並解析頁面內容，帶重試機制和隨機 User-Agent"""
        if not self.session:
            await self.create_session()
        
        retries = 0
        while retries < MAX_RETRIES:
            try:
                # 使用隨機 User-Agent
                headers = HEADERS.copy()
                headers['User-Agent'] = self._get_random_user_agent()
                
                # 添加隨機參數以避免緩存
                params = {
                    "_": int(time.time() * 1000),
                    "rand": random.randint(1000, 9999)
                }
                
                # 添加更多隨機請求頭
                headers['Accept-Encoding'] = random.choice(['gzip, deflate', 'br, gzip, deflate', 'gzip, deflate, br'])
                headers['Accept-Language'] = random.choice(['zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7', 'zh-TW,zh;q=0.8,en;q=0.6', 'en-US,en;q=0.9,zh-TW;q=0.8,zh;q=0.7'])
                
                async with self.semaphore:
                    # 增加隨機延遲，模擬真實用戶行為
                    await asyncio.sleep(1 + random.random() * 2)
                    
                    async with self.session.get(url, headers=headers, params=params, timeout=TIMEOUT) as response:
                        if response.status == 200:
                            html = await response.text()
                            soup = BeautifulSoup(html, 'html.parser')
                            
                            # 檢查頁面是否有效
                            if self._is_valid_page(soup, url):
                                return soup
                            else:
                                logger.warning(f"無效的頁面內容: {url}")
                                retries += 1
                        else:
                            logger.warning(f"請求失敗: {url}, 狀態碼: {response.status}")
                            retries += 1
            except asyncio.TimeoutError:
                logger.warning(f"請求超時: {url}, 重試 {retries+1}/{MAX_RETRIES}")
                retries += 1
                # 超時後增加等待時間
                await asyncio.sleep(RETRY_DELAY * (retries + 1))
            except Exception as e:
                logger.error(f"請求出錯: {url}, 錯誤: {e}, 重試 {retries+1}/{MAX_RETRIES}")
                retries += 1
                await asyncio.sleep(RETRY_DELAY)
        
        logger.error(f"已達到最大重試次數，無法獲取頁面: {url}")
        return None
        

        
    def _get_random_user_agent(self) -> str:
        """獲取隨機 User-Agent"""
        # 使用導入的擴展 User-Agent 列表
        return random.choice(USER_AGENTS)
    
    def _is_valid_page(self, soup: BeautifulSoup, url: str) -> bool:
        """檢查頁面是否有效"""
        # 如果是電影詳情頁面，檢查是否有電影標題
        if '/movie/' in url and not '/now' in url:
            return soup.select_one('.filmTitle') is not None
        # 如果是電影列表頁面，檢查是否有電影連結
        elif '/now/' in url or '/now2/' in url:
            return len(soup.find_all('a', href=re.compile(r'/movie/[a-zA-Z0-9]+/'))) > 0
        return True  # 其他頁面預設為有效
                
    async def get_movie_list(self, page_url: str) -> List[Dict[str, Any]]:
        """獲取電影列表"""
        if "first-run" in page_url:
            return await self._get_first_run_movies(page_url)
        else:
            return await self._get_movies_from_page(page_url)
    
    async def _get_first_run_movies(self, page_url: str) -> List[Dict[str, Any]]:
        """獲取首輪電影列表，包含處理「更多影片」按鈕"""
        # 先獲取第一頁的電影
        movies = await self._get_movies_from_page(page_url)
        logger.info(f"第一頁找到 {len(movies)} 部電影")
        
        # 處理「更多影片」按鈕，獲取後續頁面
        soup = await self.fetch_page(page_url)
        if not soup:
            logger.error(f"無法解析頁面: {page_url}")
            return movies
        
        # 尋找「更多影片」按鈕
        more_button = soup.select_one(".listTab a[onclick*='grabFile']")
        if more_button:
            # 從onclick屬性中提取URL
            onclick = more_button.get('onclick', '')
            url_match = re.search(r"grabFile\('([^']+)',[^)]+\)", onclick)
            if url_match:
                more_url = url_match.group(1)
                if not more_url.startswith('http'):
                    more_url = urljoin(BASE_URL, more_url)
                
                logger.info(f"找到更多影片按鈕，URL: {more_url}")
                more_movies = await self._get_movies_from_page(more_url)
                logger.info(f"更多影片頁面找到 {len(more_movies)} 部電影")
                
                # 合併電影列表
                movies.extend(more_movies)
        
        logger.info(f"首輪電影共找到 {len(movies)} 部電影")
        return movies
    
    async def _get_movies_from_page(self, page_url: str) -> List[Dict[str, Any]]:
        """從指定頁面獲取電影列表"""
        soup = await self.fetch_page(page_url)
        if not soup:
            logger.error(f"無法解析頁面: {page_url}")
            return []
        
        # 對網頁內容進行除錯調試
        logger.debug(f"頁面標題: {soup.title.text if soup.title else 'No title'}")
        
        # 嘗試不同的選擇器來找到電影項目
        selectors = [
            "article.filmList",  # 根據分析結果的主要選擇器
            ".filmList",  # 備用選擇器
            ".filmList li",  # 原始選擇器
            ".filmListPA li",  # 原始備用選擇器
            "li.filmList",  # 可能的變化
            "div.filmList",  # 可能的變化
            "ul.filmList li"  # 可能的變化
        ]
        
        movie_items = []
        for selector in selectors:
            items = soup.select(selector)
            if items:
                logger.info(f"使用選擇器 '{selector}' 找到 {len(items)} 個項目")
                movie_items = items
                break
        
        if not movie_items:
            # 如果使用選擇器找不到，嘗試直接尋找所有包含電影連結的元素
            movie_links = soup.find_all('a', href=re.compile(r'/movie/[a-zA-Z0-9]+/'))
            if movie_links:
                logger.info(f"直接找到 {len(movie_links)} 個電影連結")
                return self._process_movie_links(movie_links, page_url)
            else:
                logger.warning(f"在頁面 {page_url} 中找不到電影項目")
                return []
        
        logger.info(f"在頁面 {page_url} 中找到 {len(movie_items)} 個電影項目")
        
        movies = []
        processed_ids = set()  # 用於跟蹤已處理的電影ID，避免重複
        
        for item in movie_items:
            try:
                # 尋找電影連結，可能在項目內或就是項目本身
                title_element = None
                if item.name == 'a' and '/movie/' in item.get('href', ''):
                    title_element = item
                else:
                    title_element = item.select_one("a[href*='/movie/']")
                
                if not title_element:
                    continue
                
                href = title_element.get("href", "")
                if not href or '/movie/' not in href:
                    continue
                
                # 提取電影ID
                atmovies_id = href.split('/')[-2] if href.endswith('/') else href.split('/')[-1]
                
                # 檢查是否為有效的電影ID（過濾非電影資料）
                if not self._is_valid_movie_id(atmovies_id):
                    logger.debug(f"跳過非電影ID: {atmovies_id}")
                    continue
                
                # 避免重複處理同一部電影
                if atmovies_id in processed_ids:
                    continue
                processed_ids.add(atmovies_id)
                
                # 獲取電影標題
                title = title_element.text.strip()
                if not title:  # 如果沒有標題，跳過
                    continue
                
                # 嘗試從標題中提取原始標題（英文標題）
                original_title = None
                title_parts = title.split(" ", 1)
                if len(title_parts) > 1 and re.search(r'[A-Za-z]', title_parts[1]):
                    original_title = title_parts[1].strip()
                
                # 尋找片長和上映日期資訊
                runtime = None
                release_date = None
                detail_url = f"https://www.atmovies.com.tw/movie/{atmovies_id}/"
                
                # 根據我們的分析，片長和上映日期資訊在 div.runtime 元素中
                # 如果 item 本身是 article.filmList，直接在其中尋找
                if item.name == 'article' and 'filmList' in item.get('class', []):
                    runtime_elem = item.select_one("div.runtime")
                else:
                    # 嘗試找到包含此電影的 article.filmList
                    parent_article = item.find_parent("article", class_="filmList")
                    if parent_article:
                        runtime_elem = parent_article.select_one("div.runtime")
                    else:
                        # 如果找不到特定結構，嘗試更寬泛的選擇器
                        runtime_elem = item.select_one("div.runtime")
                
                if runtime_elem and runtime_elem.text.strip():
                    runtime_date_text = runtime_elem.text.strip()
                    logger.info(f"找到片長和上映日期資訊: {runtime_date_text}")
                    
                    # 提取片長
                    runtime_match = re.search(r"片長[\s\xa0]*[\:|：]?[\s\xa0]*(\d+)[\s\xa0]*分", runtime_date_text)
                    if runtime_match:
                        runtime = int(runtime_match.group(1))
                        logger.info(f"提取到片長: {runtime} 分鐘")
                    
                    # 提取上映日期 - 先嘗試 MM/DD/YYYY 格式
                    date_match = re.search(r"上映日期[\s\xa0]*[\:|：]?[\s\xa0]*([\d/]+)", runtime_date_text)
                    if date_match:
                        date_str = date_match.group(1)
                        logger.info(f"提取到上映日期字串: {date_str}")
                        try:
                            # 處理日期格式 (例如: 5/14/2025 或 2025/05/14)
                            if '/' in date_str:
                                parts = date_str.split('/')
                                if len(parts) == 3:  # 可能是 MM/DD/YYYY 或 YYYY/MM/DD
                                    if len(parts[0]) == 4:  # YYYY/MM/DD
                                        year = parts[0]
                                        month = parts[1].zfill(2)
                                        day = parts[2].zfill(2)
                                    else:  # MM/DD/YYYY
                                        month = parts[0].zfill(2)
                                        day = parts[1].zfill(2)
                                        year = parts[2] if len(parts[2]) == 4 else "2025"
                                elif len(parts) == 2:  # MM/DD (年份假設為當前年份)
                                    month = parts[0].zfill(2)
                                    day = parts[1].zfill(2)
                                    year = "2025"  # 假設為2025年
                                release_date = f"{year}-{month}-{day}"
                                logger.info(f"格式化上映日期: {release_date}")
                        except Exception as e:
                            logger.error(f"解析日期出錯: {date_str}, 錯誤: {e}")
                else:
                    # 如果在列表頁面找不到資訊，可以考慮從詳情頁面獲取
                    # 但根據你的要求，我們不會爬取詳情頁面
                    logger.debug(f"在電影 {atmovies_id} 中找不到片長和上映日期資訊")
                    
                    # 嘗試從項目的其他部分尋找資訊
                    item_text = item.text.strip()
                    
                    # 嘗試從整個項目文本中提取片長
                    if not runtime:
                        runtime_match = re.search(r"片長[\s\xa0]*[\:|：]?[\s\xa0]*(\d+)[\s\xa0]*分", item_text)
                        if runtime_match:
                            runtime = int(runtime_match.group(1))
                            logger.info(f"從項目文本提取到片長: {runtime} 分鐘")
                    
                    # 嘗試從整個項目文本中提取上映日期
                    if not release_date:
                        date_match = re.search(r"上映日期[\s\xa0]*[\:|：]?[\s\xa0]*([\d/]+)", item_text)
                        if date_match:
                            date_str = date_match.group(1)
                            try:
                                # 處理日期格式
                                if '/' in date_str:
                                    parts = date_str.split('/')
                                    if len(parts) == 3:  # 可能是 MM/DD/YYYY 或 YYYY/MM/DD
                                        if len(parts[0]) == 4:  # YYYY/MM/DD
                                            year = parts[0]
                                            month = parts[1].zfill(2)
                                            day = parts[2].zfill(2)
                                        else:  # MM/DD/YYYY
                                            month = parts[0].zfill(2)
                                            day = parts[1].zfill(2)
                                            year = parts[2] if len(parts[2]) == 4 else "2025"
                                    elif len(parts) == 2:  # MM/DD
                                        month = parts[0].zfill(2)
                                        day = parts[1].zfill(2)
                                        year = "2025"  # 假設為2025年
                                    release_date = f"{year}-{month}-{day}"
                                    logger.info(f"從項目文本提取到上映日期: {release_date}")
                            except Exception as e:
                                logger.error(f"解析日期出錯: {date_str}, 錯誤: {e}")
                
                # 建立電影資訊字典
                movie_data = {
                    "atmovies_id": atmovies_id,
                    "title": title,
                    "original_title": original_title,
                    "runtime": runtime,
                    "release_date": release_date,
                    "detail_url": detail_url
                }
                
                # 記錄獲取到的資訊
                logger.debug(f"\n獲取電影資訊: {atmovies_id}")
                logger.debug(f"  標題: {title}")
                logger.debug(f"  原始標題: {original_title}")
                logger.debug(f"  片長: {runtime}")
                logger.debug(f"  上映日期: {release_date}")
                
                movies.append(movie_data)
            except Exception as e:
                logger.error(f"解析電影項目時出錯: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        logger.info(f"在頁面 {page_url} 中找到 {len(movies)} 部有效電影")
        return movies
        
    def _process_movie_links(self, movie_links: List, page_url: str) -> List[Dict[str, Any]]:
        """處理電影連結列表"""
        movies = []
        processed_ids = set()
        
        for link in movie_links:
            try:
                href = link.get('href', '')
                if not href or '/movie/' not in href:
                    continue
                    
                # 提取電影ID
                atmovies_id = href.split('/')[-2] if href.endswith('/') else href.split('/')[-1]
                
                # 檢查是否為有效的電影ID（過濾非電影資料）
                if not self._is_valid_movie_id(atmovies_id):
                    continue
                
                # 避免重複處理同一部電影
                if atmovies_id in processed_ids:
                    continue
                processed_ids.add(atmovies_id)
                
                # 獲取電影標題
                title = link.text.strip()
                if not title:  # 如果沒有標題，跳過
                    continue
                    
                # 嘗試從標題中提取原始標題（英文標題）
                original_title = None
                title_parts = title.split(" ", 1)
                if len(title_parts) > 1 and re.search(r'[A-Za-z]', title_parts[1]):
                    original_title = title_parts[1].strip()
                
                # 建立電影資訊字典
                movie_data = {
                    "atmovies_id": atmovies_id,
                    "full_title": title,
                    "chinese_title": title_parts[0].strip() if title_parts else title.strip(),
                    "english_title": original_title,
                    "runtime": None,  # 無法從連結中直接獲取
                    "release_date": None,  # 無法從連結中直接獲取
                    "detail_url": f"https://www.atmovies.com.tw/movie/{atmovies_id}/"
                }
                
                movies.append(movie_data)
            except Exception as e:
                logger.error(f"處理電影連結時出錯: {e}")
        
        return movies
        
    def _is_valid_movie_id(self, atmovies_id: str) -> bool:
        """檢查是否為有效的電影ID"""
        # 已知的非電影ID列表
        invalid_ids = [
            'newmovie', 'list', 'listall', 'parasite', 'now2', 'new'
        ]
        
        # 如果在已知的非電影ID列表中，返回 False
        if atmovies_id in invalid_ids:
            return False
            
        # 有效的電影ID通常是由字母開頭加上數字組成
        # 例如：fmen33092501，fako92197800
        valid_pattern = re.compile(r'^f[a-z]{2,3}\d{8}$')
        return bool(valid_pattern.match(atmovies_id))
    
    async def save_movie_to_db(self, movie_data: Dict[str, Any]) -> bool:
        """將電影資訊存入資料庫"""
        try:
            # 檢查電影是否已存在
            self.cursor.execute(
                "SELECT id FROM movies WHERE atmovies_id = %s",
                (movie_data["atmovies_id"],)
            )
            existing_movie = self.cursor.fetchone()
            
            if existing_movie:
                # 更新現有電影
                self.cursor.execute(
                    """
                    UPDATE movies 
                    SET full_title = %s, chinese_title = %s, english_title = %s, runtime = %s, release_date = %s, updated_at = NOW()
                    WHERE atmovies_id = %s
                    RETURNING id
                    """,
                    (
                        movie_data["full_title"],
                        movie_data["chinese_title"],
                        movie_data["english_title"],
                        movie_data["runtime"],
                        movie_data["release_date"],
                        movie_data["atmovies_id"]
                    )
                )
                self.conn.commit()
                logger.info(f"更新電影資訊: {movie_data['full_title']}")
                return True
            else:
                # 新增電影
                self.cursor.execute(
                    """
                    INSERT INTO movies (atmovies_id, full_title, chinese_title, english_title, runtime, release_date, created_at, updated_at, source)
                    VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW(), 'atmovies')
                    """,
                    (
                        movie_data["atmovies_id"],
                        movie_data["full_title"],
                        movie_data["chinese_title"],
                        movie_data["english_title"],
                        movie_data["runtime"],
                        movie_data["release_date"]
                    )
                )
                self.conn.commit()
                logger.info(f"新增電影: {movie_data['full_title']}")
                return True
        except Exception as e:
            self.conn.rollback()
            logger.error(f"存入電影資訊時出錯: {e}")
            return False
            
    async def export_to_csv(self, movies: List[Dict[str, Any]]) -> str:
        """將電影資料匯出為CSV檔案"""
        try:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"atmovies_movies_{timestamp}.csv"
            
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['atmovies_id', 'title', 'original_title', 'runtime', 'release_date', 'detail_url']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for movie in movies:
                    writer.writerow(movie)
                    
            logger.info(f"已將 {len(movies)} 部電影資料匯出至 {filename}")
            return filename
        except Exception as e:
            logger.error(f"匯出CSV檔案時出錯: {e}")
            return ""
    
    async def process_movie_list(self, page_url: str) -> int:
        """處理電影列表頁面"""
        # 獲取電影列表
        movies = await self.get_movie_list(page_url)
        processed_count = 0
        failed_count = 0
        
        if not movies:
            logger.warning(f"無法從頁面獲取電影列表: {page_url}")
            return processed_count
            
        logger.info(f"共找到 {len(movies)} 部電影，開始處理...")
        
        # 處理每部電影
        for index, movie in enumerate(movies):
            try:
                logger.info(f"[進度 {index+1}/{len(movies)}] 處理電影: {movie['title']} ({movie['atmovies_id']})")
                
                # 檢查資料完整性
                if not self._validate_movie_data(movie):
                    logger.warning(f"電影資料不完整，已跳過: {movie['title']}")
                    failed_count += 1
                    continue
                
                # 存入資料庫
                if await self.save_movie_to_db(movie):
                    processed_count += 1
                    logger.info(f"成功處理電影: {movie['title']} ({movie['atmovies_id']})")
                    
                    # 打印詳細資訊供檢查
                    logger.info(f"  標題: {movie['title']}")
                    logger.info(f"  原始標題: {movie['original_title']}")
                    logger.info(f"  上映日期: {movie['release_date']}")
                    logger.info(f"  片長: {movie['runtime']} 分鐘")
                else:
                    failed_count += 1
                
                # 由於不需要訪問詳情頁面，可以減少延遲
                await asyncio.sleep(0.2 + random.random() * 0.3)
            except Exception as e:
                logger.error(f"處理電影時出錯: {e}")
                failed_count += 1
        
        logger.info(f"頁面 {page_url} 處理完成: 成功 {processed_count} 部，失敗 {failed_count} 部")
        return processed_count
        
    def _validate_movie_data(self, movie_data: Dict[str, Any]) -> bool:
        """驗證電影資料是否完整"""
        # 檢查必要欄位
        required_fields = ['atmovies_id', 'title']
        for field in required_fields:
            if not movie_data.get(field):
                logger.warning(f"缺少必要欄位: {field}")
                return False
        
        # 檢查是否有至少一個附加資訊（上映日期或片長）
        if not movie_data.get('release_date') and not movie_data.get('runtime'):
            logger.warning(f"缺少上映日期和片長資訊: {movie_data['title']}")
            # 不返回 False，因為這些不是必要的
        
        return True
    
    async def export_to_csv(self, movies: List[Dict[str, Any]]) -> str:
        """將電影資料匯出為CSV檔案"""
        try:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"atmovies_movies_{timestamp}.csv"
            
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['atmovies_id', 'title', 'original_title', 'runtime', 'release_date', 'detail_url']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for movie in movies:
                    writer.writerow(movie)
                    
            logger.info(f"已將 {len(movies)} 部電影資料匯出至 {filename}")
            return filename
        except Exception as e:
            logger.error(f"匯出CSV檔案時出錯: {e}")
            return ""
    
    async def run(self):
        """執行電影爬蟲"""
        try:
            # 連接資料庫
            if not await self.connect_to_db():
                return
            
            # 設置日誌層級為 DEBUG，以查看更多詳細資訊
            logger.setLevel(logging.INFO)
            
            # 用於收集所有電影資料以匯出CSV
            all_movies = []
            
            # 處理首輪電影
            logger.info("開始爬取首輪電影清單...")
            first_run_movies = await self._get_first_run_movies(FIRST_RUN_URL)
            first_run_count = 0
            
            for movie in first_run_movies:
                # 檢查資料完整性
                if self._validate_movie_data(movie):
                    # 存入資料庫
                    if await self.save_movie_to_db(movie):
                        first_run_count += 1
                        all_movies.append(movie)
            
            logger.info(f"共處理了 {first_run_count} 部首輪電影")
            
            # 處理二輪電影
            logger.info("開始爬取二輪電影清單...")
            second_run_movies = await self._get_first_run_movies(SECOND_RUN_URL)
            second_run_count = 0
            
            for movie in second_run_movies:
                # 檢查資料完整性
                if self._validate_movie_data(movie):
                    # 存入資料庫
                    if await self.save_movie_to_db(movie):
                        second_run_count += 1
                        all_movies.append(movie)
            
            logger.info(f"共處理了 {second_run_count} 部二輪電影")
            
            # 統計結果
            total_count = first_run_count + second_run_count
            logger.info(f"爬蟲完成，共處理了 {total_count} 部電影")
            
            # 查詢資料庫中的電影數量
            self.cursor.execute("SELECT COUNT(*) FROM movies WHERE source = 'atmovies'")
            db_count = self.cursor.fetchone()['count']
            logger.info(f"資料庫中共有 {db_count} 部來自 ATMovies 的電影")
            
            # 匯出CSV檔案
            csv_file = await self.export_to_csv(all_movies)
            if csv_file:
                logger.info(f"已將爬蟲結果匯出至 {csv_file}")
            
        except Exception as e:
            logger.error(f"爬蟲運行時發生錯誤: {e}")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            # 關閉資源
            await self.close_session()
            self.close_db_connection()

async def main():
    """主函數"""
    scraper = ATMoviesMovieScraper()
    await scraper.run()

if __name__ == "__main__":
    # 在 Windows 上需要使用事件循環策略
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # 執行主函數
    asyncio.run(main())
